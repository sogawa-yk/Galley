# Galley（ゲラ） — プリセールスエンジニア向けAI支援システム構想レポート

## 1. 背景と目的

クラウドベンダーのプリセールスエンジニアが、技術検証やデモの作成を迅速かつ高品質に行えるよう、LLMおよびその周辺エコシステム（MCP、エージェント等）を活用した社内システム「**Galley**」を構築する。

> **名前の由来**: Galley（ゲラ）は印刷用語で「校正刷り」を意味する。本番前の試作版を素早く作り上げ、確認・修正を経て世に出すというプロセスが、プリセールスにおけるデモ作成のワークフロー（要件ヒアリング → アーキテクチャ設計 → デモ環境デプロイ）と重なる。

プリセールス業務では、顧客の要件に合わせたデモ環境の準備、技術検証（PoC）の実施、提案資料の作成に多くの時間がかかっている。本システムは、これらの作業をAIで加速・自動化することを目指す。

---

## 2. システムの全体構想

### 2.1 主要機能

本システムで実現を目指す機能は、以下の6領域に整理される。

#### デモ環境の自動構築・管理

- 自然言語でのデモ環境リクエスト（例：「3層Webアプリで、DBはマネージドPostgreSQL、認証はOIDC連携、CDN付き」）から、IaCテンプレートを自動生成しデプロイまで実行
- 過去のデモ環境のカタログ化と類似案件の検索・再利用
- デモ終了後の環境自動クリーンアップによるコスト管理

#### 技術検証（PoC）の加速

- MCPサーバー経由でクラウドサービスのAPI/CLIを操作し、リソース作成・設定変更・負荷テスト・メトリクス収集をエージェントが自動実行
- 検証結果の自動レポート生成（ログ、メトリクス、スクリーンショットの収集と文書化）
- 過去のPoC結果やトラブルシューティング知見のRAG検索

#### 提案資料・ドキュメント生成

- 自然言語からのアーキテクチャ構成図自動生成
- 技術比較表の自動作成
- RFP/RFI対応支援（社内ドキュメント・リリースノートのRAG検索による回答ドラフト生成）

#### ライブデモ支援

- デモ中のリアルタイム情報表示アシスタント
- 障害シミュレーション（フェイルオーバー等）のエージェント実行

#### 対話型ヒアリング（選択式ウィザード）

- 後述（セクション3で詳述）

#### 社内ナレッジハブ

- 社内Wiki、チャットツール、過去の提案書、公式ドキュメントの横断検索
- 新サービス・機能アップデートと関連案件の自動紐づけ通知

### 2.2 全体アーキテクチャ（将来像）

```
ユーザー（プリセールスエンジニア）
    ↓ 自然言語 / 選択式入力
チャットUI（Web / Slack / Teams）
    ↓
LLMオーケストレーター（エージェント）
    ├── MCP Server: クラウドAPI操作
    ├── MCP Server: IaC生成・デプロイ
    ├── MCP Server: 社内ドキュメント検索（RAG）
    ├── MCP Server: 資料生成（PPTX / DOCX / PDF）
    ├── MCP Server: メトリクス収集・可視化
    └── MCP Server: チケット / CRM連携（Salesforce等）
```

---

## 3. 対話型ヒアリング機能（選択式ウィザード）

### 3.1 コンセプト

自然言語で要件を詳細に記述するのは認知負荷が高い。本システムでは、ユーザーが概要だけを伝えた後、AI側が選択式の質問を通じて要件を段階的に具体化する「対話型ウィザード」を採用する。

プリセールスエンジニアは技術に精通しているため、選択肢の意味は理解できる。選択式にすることで、要件定義が「記述」ではなく「認識の確認」になり、数分で精度の高い要件定義が完了する。また、AI側が質問を設計することで、ベテランでも見落としがちな観点（DR要件、コンプライアンス、ログ保持期間等）の聞き漏れを防ぐ効果もある。

### 3.2 対話フロー例

```
ユーザー: 「在庫管理システムをクラウドネイティブ化する案件のデモを作りたい」

AI: 案件の概要を理解しました。いくつか確認させてください。

Q1. お客様の業種は？
  ○ 製造業  ○ 小売・EC  ○ 物流  ○ その他
→ 「小売・EC」を選択

Q2. 想定される同時接続ユーザー数は？
  ○ ~100  ○ 100~1,000  ○ 1,000~10,000  ○ 10,000+
→ 「1,000~10,000」を選択

Q3. セール時など急激なスパイクはありますか？
  ○ はい、予測可能なタイミングで  ○ はい、予測不可能  ○ いいえ
→ 「はい、予測可能なタイミングで」を選択

Q4. 既存DBは？
  ○ Oracle  ○ SQL Server  ○ PostgreSQL  ○ MySQL  ○ その他

...（10問程度で完了）
```

### 3.3 設計上の重要ポイント

#### 質問生成のハイブリッド方式

質問のカテゴリと順序はテンプレートで定義し、具体的な選択肢はLLMがコンテキストに応じて動的に生成する。たとえば「DB選定」という質問カテゴリは必ず出すが、選択肢は案件種別に応じて絞り込む。

#### 回答の依存関係処理

前の回答によって後続の質問が変化する。「マルチリージョン: Yes」→「レプリケーション戦略は？」が追加される等。本質的には有向グラフの探索であり、LLMがナビゲーターとなる。

#### 自然言語への切り替え

選択肢では表現しきれない特殊要件に対応するため、各質問に「その他（自由入力）」を用意し、途中でのモード切り替えも可能にする。

#### レコメンド表示

過去の類似案件での選択傾向を表示する。例：「小売EC × 在庫管理の過去5件中4件がPostgreSQLを選択」。意思決定の加速と、組織ナレッジの自然な循環を促進する。

### 3.4 技術的な実現方法

LLMに構造化JSON形式で質問を出力させ、フロントエンドがウィジェットとしてレンダリングする。

```json
{
  "question": "セール時など急激なスパイクはありますか？",
  "type": "single_select",
  "options": [
    {
      "label": "はい、予測可能",
      "value": "predictable_spike",
      "next_hint": "scaling_schedule"
    },
    {
      "label": "はい、予測不可能",
      "value": "unpredictable_spike",
      "next_hint": "auto_scaling"
    },
    { "label": "いいえ", "value": "no_spike", "next_hint": "fixed_capacity" }
  ]
}
```

---

## 4. 「わからない」への対応と推測の妥当性担保

### 4.1 課題

プリセールスの初回ヒアリング段階では、顧客自身が要件を明確にできていないことが多い。「わからないから先に進めない」システムでは実用性がなく、かといって適当に埋めるとデモの方向性がズレる。

本システムに求められるのは、「わからない」を受け入れつつ、妥当な推測で補完し、その推測の根拠を透明にすることである。

### 4.2 推測の根拠レイヤー

推測の根拠には信頼度の段階がある。

| 信頼度 | 根拠の種類                           | ラベル      | 例                                              |
| ------ | ------------------------------------ | ----------- | ----------------------------------------------- |
| 高     | 社内過去案件の統計データ             | 📊 社内実績 | 「類似案件6件の中央値が7,000 TPS」              |
| 中     | 公開事例・リファレンスアーキテクチャ | 📄 公開事例 | 「○○社がピーク時8,000 TPSと公表」               |
| 低     | 業界の一般的なベストプラクティス     | 💡 一般推計 | 「SKU数10万点規模では5,000~12,000 TPSが典型的」 |

根拠のラベルを明示することで、ユーザーが推測の信頼度を直感的に判断できるようにする。また、具体的なソースが見つからない場合は正直にその旨を示し、ハルシネーションのリスクを抑制する。

### 4.3 推測の承認フロー

推測は自動で埋めるのではなく、根拠を提示した上でユーザーに承認を求める。

```
Q5. ピーク時のトランザクション数は？
  ○ ~1,000 TPS  ○ 1,000~5,000 TPS  ○ 5,000~10,000 TPS  ○ わからない
→ 「わからない」を選択

AI: 以下の根拠から「5,000~10,000 TPS」と仮定します。

  📊 社内実績: 小売EC×在庫管理の類似案件6件の中央値が約7,000 TPS
  📄 公開事例: ○○社（年商300億・EC比率40%）がピーク時8,000 TPSと公表
  💡 一般推計: SKU数10万点規模のECでは繁忙期5,000~12,000 TPSが典型的

  → この仮定でよいですか？
    ○ この仮定で進める  ○ もう少し大きく見積もる  ○ もう少し小さく見積もる
```

これにより、プリセールスが顧客にデモを見せる際に「なぜこの構成にしたか」を自身で説明できるようになる。

### 4.4 要件サマリーでの区別

ヒアリング完了後のサマリーでは、確定事項・推測・未確認を明確に区別する。

```
【要件サマリー】

✅ 確定事項
  - 業種: 小売EC
  - 既存DB: Oracle 19c
  - マルチリージョン: 不要（国内のみ）

🔶 推測に基づく仮定（要確認）
  - ピーク時TPS: ~7,000（根拠: 類似案件実績）
  - データ総量: ~2TB（根拠: SKU数と取引履歴からの推計）
  - 可用性要件: 99.95%（根拠: 業界標準）

⚠️ 未確認（デモ後にヒアリング推奨）
  - 既存システムとの連携IF数
  - コンプライアンス要件（PCI DSS等）
```

このサマリー自体が「次回の顧客ヒアリングで確認すべき事項リスト」としても機能し、デモ準備だけでなく営業プロセス全体を前に進めるツールとなる。

---

## 5. 社内ナレッジの活用に関する課題と戦略

### 5.1 現状の制約

社内のナレッジは以下の3つの状態に分かれている。

| 状態                     | 内容                                                                                  | アクセス性 |
| ------------------------ | ------------------------------------------------------------------------------------- | ---------- |
| 構造化済み・アクセス不可 | 案件DB（案件情報はあるが技術詳細は不足。UI経由では閲覧可能だがBot/APIアクセスは不可） | ×          |
| 非構造化・アクセス可能   | 提案書（PPTX）、検証レポート等（ファイルサーバーやSharePoint等に散在）                | △          |
| 暗黙知                   | 意思決定の背景、トラブルシューティングの経験知（人の頭の中にのみ存在）                | ×          |

### 5.2 段階的なアプローチ

#### 第1段階：既存資料からのナレッジ抽出

PowerPoint等の既存資料を処理パイプラインで取り込む。LLMによる構造化抽出（案件種別、アーキテクチャ、採用技術等）を行い、Human-in-the-Loopでレビュー・補正する。全資料を一括対象にせず、品質の高い提案書を選定して開始する。

#### 第2段階：案件DBとの連携

Bot/APIアクセスの正式申請を並行で進めつつ、当面は定期エクスポート（CSV/JSON）での同期、または案件DBの情報は索引（案件の存在確認）として割り切り、技術詳細は別のデータストアで管理する。

#### 第3段階：「使いながら溜まる」仕組みの構築

本システム自体をナレッジ蓄積の入口にする。デモを作るたびに、構造化済みのヒアリング結果、採用アーキテクチャ、構成変更履歴が自動的に蓄積される。時間の経過とともに、既存資料から抽出した「レガシーナレッジ」から、本システム経由で生まれた「ネイティブナレッジ」へと比重が移り、データ品質も均一化していく。

### 5.3 ナレッジ基盤のアーキテクチャ

```
【入口】
  既存PPTX/DOCX ──→ 抽出パイプライン ──→ LLM構造化 → 人がレビュー ─┐
  案件DB（エクスポート）──→ 索引データとして取り込み ─────────────┤
  本システムでの新規デモ作成 ──→ 自動的に構造化データとして蓄積 ──────┘
                                                                    ↓
                                                          ナレッジストア
                                                         ┌─────────────┐
                                                         │ 構造化DB     │ ← 案件メタデータ、
                                                         │（RDB）       │   選定理由、構成パラメータ
                                                         ├─────────────┤
                                                         │ ベクトルDB   │ ← 資料本文、検証結果、
                                                         │              │   自由記述のナレッジ
                                                         └─────────────┘
                                                                ↓
                                                    RAG + 構造化検索の併用で
                                                    推測の根拠提示に利用
```

### 5.4 注意点

- **ナレッジの鮮度管理**: クラウドサービスの変化は速く、古い事例がそのまま有効とは限らない。タイムスタンプを必ず付与し、推測根拠として使用する際には情報の時点を明示する
- **インセンティブ設計**: 既存資料のレビュー・補正は追加の手間がかかるため、ナレッジ貢献度の可視化等で負担感を軽減する工夫が必要

---

## 6. MVP戦略

### 6.1 基本方針

まずは個人の業務効率化ツールとして小さく始め、価値が実証されてからチーム・社内へ展開する。自分が毎日使うことでフィードバックループを速く回し、本当に必要な機能を見極める。

### 6.2 MVPのスコープ

MVPでは「選択式ヒアリング → アーキテクチャ決定 → アウトプット生成」のコアフロー1本に絞る。

```
自分（チャットUI）
  ↓ 「在庫管理のクラウドネイティブ化デモを作りたい」
LLM（選択式ヒアリングを実施）
  ↓ ヒアリング結果JSON
LLM（アーキテクチャ生成）
  ↓
出力:
  ・要件サマリー（確定 / 推測 / 未確認の区別付き）
  ・構成図（Mermaid等）
  ・IaCテンプレートのドラフト
  ・（余裕があれば）提案スライドの骨格
```

推測の根拠は、初期段階ではLLM自身の知識とWeb検索による公開事例で対応する。社内ナレッジの接続はコアフローが安定した後に着手する。

### 6.3 想定技術スタック

| コンポーネント | 選択肢                                | 備考                                                  |
| -------------- | ------------------------------------- | ----------------------------------------------------- |
| LLM            | Claude API                            | 構造化出力（JSON mode）で選択式質問を制御             |
| チャットUI     | 簡易Webアプリ（Next.js等）/ Slack Bot | 選択式UIを実現するため最低限のフロントエンドが必要    |
| ツール連携     | Function Calling                      | MVP段階ではMCPサーバーは不要。チーム展開時にMCPへ移行 |
| IaC生成        | LLMによる直接生成                     | 自社クラウド向けのプロンプトとバリデーションが肝      |

### 6.4 MVPで最初に設計すべきこと

ヒアリング結果のJSONスキーマを最初からきちんと定義しておくこと。このスキーマが後続のすべて（アーキテクチャ生成、IaCテンプレート生成、将来のナレッジ蓄積）の基盤となる。「案件種別」「非機能要件」「技術制約」等のカテゴリ分けと、各項目のenum・値域は初期段階で設計する。UIやデプロイの仕組みは後から変更可能なので、初期は簡素でよい。

### 6.5 展開ロードマップ

```
Phase 1: 個人利用MVP
  → コアフロー（ヒアリング → アーキテクチャ → アウトプット）
  → LLM知識 + Web検索ベースの推測根拠

Phase 2: チーム展開
  → 既存PPTX等からのナレッジ抽出パイプライン
  → ナレッジを活用したレコメンドと推測根拠の強化
  → MCPサーバー化によるツール連携の拡充

Phase 3: 社内展開
  → 案件DB連携
  → デモ環境の自動構築・管理
  → ライブデモ支援、提案資料の自動生成
  → 「使いながら溜まる」ナレッジ循環の確立
```
